# ViG3D-UNet

This repository provides the offical Pytorch implementation of ViG3D-UNet in the following Paper:

**ViG3D-UNet: Volumetric Vascular Connectivity-Aware Segmentation via 3D Vision Graph Representation**<br/>
Bowen Liu, Chunlei Meng, Wei Lin, Hongda Zhang, Ziqing Zhou, Zhongxue Gan, Chun Ouyang<br/>
Fudan University<br/>
IEEE Journal of Biomedical and Health Informatics (https://ieeexplore.ieee.org/document/11155174)<br/>

## News

2025.09.10 Early Access on IEEE Eplore.

2025.09.04 üåü Accepted by IEEE JBHI.

2025.04.12 Initial Submission on IEEE JBHI.

## Checklist
- ‚úÖ Model Source code release.
- [ ] Inference code is coming SOON 
- [ ] Release ViG3D-UNet_Large and ViG3D-UNet_Large_medium checkpoints.
- [ ] Training  code.

## How to use ViG3D-UNet(To be done...)
### 1. Requirements

### 2. Installation

### 3. Inference

### 4.Training

### 5.Evaluation


## Contributions
**This project is still under development. Please feel free to raise issues or submit pull requests to contribute to our codebase.**

Some insights about 3D CNN module is originated from [nnUNet](https://github.com/MIC-DKFZ/nnUNet) and the 3D Vision GNN(ViG3D) module is originated from [Vision GNN](https://github.com/huawei-noah/Efficient-AI-Backbones).

## BraTS Experiments (WIP)
The BraTS workflow is under active development with config-driven training runs. Use the dry-run config to verify the pipeline and output layout:

```bash
python -m src.train --config configs/brats/dry_run.yaml
```

The dry run writes a run folder under `runs/<exp_name>/<timestamp>/` with a config copy, environment info, and logs. It will log a single batch shape and exit.

## Citation
If you find this repository/work helpful in your research, welcome to cite these papers and give a ‚≠ê.
